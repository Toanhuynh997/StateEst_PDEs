{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5110524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import eye, diags, block_diag, hstack\n",
    "from scipy.sparse.csgraph import reverse_cuthill_mckee\n",
    "from scipy.sparse.linalg import gmres\n",
    "# from scipy.sparse.csgraph import symmetrix_degree_order\n",
    "import importlib\n",
    "import time\n",
    "import NavierStokes_Periodic_Solver as NS_Per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58058b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NavierStokes_Periodic_Solver' from '/Users/huynh/Desktop/Python/EnSF/NavierStokes/Periodic/NavierStokes_Periodic/NavierStokes_Periodic_Solver.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(NS_Per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e8c96",
   "metadata": {},
   "source": [
    "## Run on MATLAB first to generate 'Permutation_Indices_RefSol_Per40.mat', then run 'EnSF_DRLM_NS_Periodic' for reference solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07357f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('Permutation_Indices_RefSol_Per40.mat')\n",
    "\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perS = data['perS'].astype(np.float64)\n",
    "# perA = data['perA'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47ef6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS -= 1\n",
    "# perA -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6de3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "Nt = T*600\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "dt = T / Nt\n",
    "TT = np.arange(0, T + dt/2, dt)\n",
    "\n",
    "alpha_BE = 1 / dt   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha_BE * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A_BE = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA_BE = A_BE.diagonal()\n",
    "D_BE = diags(dA_BE, 0, shape=A_BE.shape, format='csr')\n",
    "E_BE = D_BE - A_BE\n",
    "Di_BE = diags(1.0 / dA_BE, 0, shape=A_BE.shape, format='csr')\n",
    "S_BE = B.dot(Di_BE.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perS, perS)\n",
    "S_perm = S_BE[rowsS, colsS].toarray()\n",
    "SS_BE = np.linalg.cholesky(S_perm).T\n",
    "SS_BEt = SS_BE.T\n",
    "DiE_BE = Di_BE.dot(E_BE)\n",
    "BDiE_BE = B.dot(DiE_BE)\n",
    "DiB_BEt = Di_BE.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "q_batch = np.full((2,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51105ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perSBE_new = perS.astype(int)\n",
    "\n",
    "perSBE_new = np.squeeze(perSBE_new, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16636753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('Permutation_Indices_RefSol_BDF2Per40.mat')\n",
    "\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perBDFS = data['perS'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3977539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perBDFS -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8563d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "Nt = T*600\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "dt = T / Nt\n",
    "TT = np.arange(0, T + dt/2, dt)\n",
    "\n",
    "alpha = 1.5 / dt   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA = A.diagonal()\n",
    "D = diags(dA, 0, shape=A.shape, format='csr')\n",
    "E = D - A\n",
    "Di = diags(1.0 / dA, 0, shape=A.shape, format='csr')\n",
    "S = B.dot(Di.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perBDFS, perBDFS)\n",
    "S_perm = S[rowsS, colsS].toarray()\n",
    "SS = np.linalg.cholesky(S_perm).T\n",
    "SSt = SS.T\n",
    "DiE = Di.dot(E)\n",
    "BDiE = B.dot(DiE)\n",
    "DiBt = Di.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "# q_batch = np.full((2,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ad0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "perBDFS_new = perBDFS.astype(int)\n",
    "\n",
    "perBDFS_new = np.squeeze(perBDFS_new, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a490871",
   "metadata": {},
   "outputs": [],
   "source": [
    "mU0, nU0 = U0.shape\n",
    "mV0, nV0 = V0.shape\n",
    "mP0, nP0 = Xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba29a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_U = np.zeros((Nt+1, mU0*nU0))\n",
    "All_V = np.zeros((Nt+1, mV0*nV0))\n",
    "All_P = np.zeros((Nt+1, mP0*nP0))\n",
    "All_q = np.zeros((Nt+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e65f28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_U[0, :] += np.reshape(U0, mU0*nU0, order='F')\n",
    "All_V[0, :] += np.reshape(V0, mV0*nV0, order='F')\n",
    "All_q[0, :] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b81fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_U = mU0*nU0\n",
    "Size_V = mV0*nV0\n",
    "Size_P = mP0*nP0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1464ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_indices(p, Nx, Ny, r):\n",
    "    \"\"\"\n",
    "    Return the flattened indices of a square neighborhood of radius r\n",
    "    around grid point p on an Nx-by-Ny grid (0-based indexing).\n",
    "\n",
    "    Parameters:\n",
    "      p  : integer in [0, Nx*Ny)\n",
    "      Nx : number of rows\n",
    "      Ny : number of columns\n",
    "      r  : localization radius (in grid cells)\n",
    "\n",
    "    Returns:\n",
    "      flat_inds : 1D array of length up to (2r+1)^2, listing all\n",
    "                  0-based flattened indices within the neighborhood.\n",
    "    \"\"\"\n",
    "    # Convert flat index p -> (i,j)\n",
    "    i = p // Ny\n",
    "    j = p % Ny\n",
    "    # Row range [i-r, i+r], clipped to [0, Nx)\n",
    "    rows = np.arange(max(0, i-r), min(Nx, i+r+1))\n",
    "    # Col range [j-r, j+r], clipped to [0, Ny)\n",
    "    cols = np.arange(max(0, j-r), min(Ny, j+r+1))\n",
    "    # Form Cartesian product\n",
    "    Ii, Jj = np.meshgrid(rows, cols, indexing='ij')\n",
    "    flat_inds = (Ii * Ny + Jj).ravel()\n",
    "    return flat_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b76f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_indices_block(p, Nx, Ny, radius):\n",
    "    ## Modify this\n",
    "    m = Nx * Ny\n",
    "    # determine component: 0,1,2\n",
    "    comp = p // m\n",
    "    # pixel idx within component\n",
    "    q = p % m\n",
    "    # local patch in component\n",
    "    base_patch = local_indices(q, Nx, Ny, radius)\n",
    "    # shift by component block\n",
    "    return base_patch + comp * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a272ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_indices_block_diffsize(p, Nx, Ny, radius):\n",
    "    \"\"\"\n",
    "    Return global indices of the neighborhood around global index p,\n",
    "    where the state is composed of 4 blocks of sizes:\n",
    "      1) Nx*Ny       on an (Nx,Ny) grid\n",
    "      2) Nx*(Ny-1)   on an (Nx,Ny-1) grid\n",
    "      3) Nx*Ny       on an (Nx,Ny) grid\n",
    "      4) 1           (scalar)\n",
    "    \"\"\"\n",
    "    # 1) block sizes\n",
    "    m1 = Nx * Ny\n",
    "    m2 = Nx * Ny\n",
    "    m3 = Nx * Ny\n",
    "    m4 = 1\n",
    "    block_sizes = [m1, m2, m3, m4]\n",
    "    # 2) compute block offsets\n",
    "    offsets = np.array([0, m1, m1 + m2, m1 + m2 + m3], dtype=int)\n",
    "\n",
    "    # 3) find which block p is in\n",
    "    for comp, size in enumerate(block_sizes):\n",
    "        if p < offsets[comp] + size:\n",
    "            break\n",
    "\n",
    "    # 4) local index within that block\n",
    "    q = p - offsets[comp]\n",
    "\n",
    "    # 5) build the neighborhood\n",
    "    if comp == 0 or comp == 2:\n",
    "        # Blocks 0 & 2: Nx x Ny grid\n",
    "        base_patch = local_indices(q, Nx, Ny, radius)\n",
    "    elif comp == 1:\n",
    "        # Block 1: Nx x (Ny-1) grid\n",
    "        base_patch = local_indices(q, Nx, Ny, radius)\n",
    "    else:\n",
    "        # Block 3: scalar\n",
    "        base_patch = np.array([0], dtype=int)\n",
    "\n",
    "    # 6) shift to global indices\n",
    "    return base_patch + offsets[comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0eecea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_k_obs(i, grid, obs_xy, scalar_idx, K):\n",
    "    \n",
    "    if i == scalar_idx:\n",
    "        return np.array([-1], dtype=int)\n",
    "    else:\n",
    "        d2 = ((obs_xy - grid[i])**2).sum(axis=1)\n",
    "        idx = np.argsort(d2)[:K]\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d06a7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LETKF_local(Xb, y, R, rho, Nx, Ny, idx_obs, grid_xy_total, obs_xy, radius):\n",
    "    \"\"\"\n",
    "    Local LETKF using a square neighborhood in model space (no obs localization).\n",
    "\n",
    "    Steps 1–2: global means and perturbations\n",
    "    Step 3  : local model-space selection via `local_indices`\n",
    "    Steps 4–8: analysis in ensemble space (obs from all dims)\n",
    "\n",
    "    Inputs:\n",
    "      Xb     : (m_g, k) forecast ensemble (m_g = Nx*Ny)\n",
    "      y      : (l_g,)    observations\n",
    "      H      : (l_g, m_g) observation operator\n",
    "      R      : (l_g, l_g) observation error covariance\n",
    "      Nx, Ny : grid dimensions\n",
    "      radius : localization radius in grid cells\n",
    "\n",
    "    Returns:\n",
    "      Xa : (m_g, k) analysis ensemble\n",
    "    \"\"\"\n",
    "    m_g, k = Xb.shape\n",
    "    # print(m_g)\n",
    "    # Step 1 & 2: global means & perturbations\n",
    "    Xb_mean = Xb.mean(axis=1, keepdims=True)      # (m_g, 1)\n",
    "    Xb_pert = Xb - Xb_mean                        # (m_g, k)\n",
    "    Yb_raw  = np.arctan(Xb[idx_obs, :])          # (l_g, k)                \n",
    "    Yb_mean = Yb_raw.mean(axis=1, keepdims=True)  # (l_g, 1)\n",
    "    Yb_pert = Yb_raw - Yb_mean                    # (l_g, k)\n",
    "\n",
    "    Xa = np.zeros_like(Xb)\n",
    "\n",
    "    # Precompute obs-space inverse\n",
    "#     Rinv = np.linalg.inv(R)\n",
    "\n",
    "    # Loop over each grid point for local analysis\n",
    "    for p in range(m_g):\n",
    "        # Step 3: pick local model-space indices\n",
    "        loc_inds = local_indices_block_diffsize(p, Nx, Ny, radius)\n",
    "        # loc_inds = local_indices_block(p, Nx, Ny, radius)\n",
    "        # print(p)\n",
    "        # Local mean & perturbations\n",
    "        xb_m_loc = Xb_mean[loc_inds, 0]           # (m_loc,)\n",
    "        Xb_loc   = Xb_pert[loc_inds, :]           # (m_loc, k)\n",
    "\n",
    "        # Step 4: use all observations (no spatial selection)\n",
    "        loc_obs = nearest_k_obs(p, grid_xy_total, obs_xy, m_g-1, 8)\n",
    "        # if p == m_g-1:\n",
    "        #     print(loc_obs)\n",
    "        yb_m_loc = Yb_mean[loc_obs, 0]                  # (l_g,)\n",
    "        Yb_loc   = Yb_pert[loc_obs, :]                        # (l_g, k)\n",
    "      \n",
    "        yo_loc = y[loc_obs, 0] # observation\n",
    "        R_loc = R[loc_obs]           # now shape (n_obs, l_g)\n",
    "        R_loc = R_loc[:, loc_obs] \n",
    "        # Steps 5–6: ensemble-space analysis covariance\n",
    "        W = np.linalg.solve(R_loc, Yb_loc)\n",
    "        C = W.T \n",
    "\n",
    "        # Step 7a: analysis perturbation matrix\n",
    "        M = (k-1)/rho * np.eye(k) + C @ Yb_loc\n",
    "        w, Q = np.linalg.eigh(M)\n",
    "        w_inv     = 1.0 / w          # for P^a = Q diag(w_inv) Q^T\n",
    "        w_inv_sqrt = 1.0 / np.sqrt(w)  # for (P^a)^{1/2}\n",
    "        \n",
    "        Pa = (Q * w_inv.reshape(1, -1)) @ Q.T \n",
    "\n",
    "        # Step 7b: mean weights\n",
    "        Wa = np.sqrt(k-1) * (Q * w_inv_sqrt.reshape(-1, 1)) @ Q.T\n",
    "        wabar = Pa @ (C @ (yo_loc - yb_m_loc))           # (k,)\n",
    "        Wana  = Wa + wabar.reshape(-1, 1)                 # (k x k)\n",
    "        \n",
    "        # Step 8: map back to model space and extract center\n",
    "        xa_loc = xb_m_loc[:, None] + Xb_loc @ Wana  # (m_loc, k)\n",
    "        # find center index within the local block\n",
    "        \n",
    "        center_idx = np.where(loc_inds == p)[0][0]\n",
    "        Xa[p, :] = xa_loc[center_idx, :]\n",
    "\n",
    "    return Xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caa8626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "# ## 100% arctangent observation\n",
    "# indices_U = np.random.permutation(Size_U)[:int(1 * Size_U)]\n",
    "# indices_V = np.random.permutation(Size_V)[:int(1 * Size_V)] + Size_U\n",
    "# indices_P = np.random.permutation(Size_P)[:int(1 * Size_P)] + Size_U + Size_V\n",
    "# indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "\n",
    "\n",
    "## 70% arctangent observation\n",
    "# indices_U = np.random.permutation(Size_U)[:int(0.7 * Size_U)]\n",
    "# indices_V = np.random.permutation(Size_V)[:int(0.7 * Size_V)] + Size_U\n",
    "# indices_P = np.random.permutation(Size_P)[:int(0.7 * Size_P)] + Size_U + Size_V\n",
    "# indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "\n",
    "\n",
    "## 7% arctangent observation\n",
    "indices_U = np.random.permutation(Size_U)[:int(0.07* Size_U)]\n",
    "indices_V = np.random.permutation(Size_V)[:int(0.07* Size_V)] + Size_U\n",
    "indices_P = np.random.permutation(Size_P)[:int(0.07* Size_P)] + Size_U + Size_V\n",
    "indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "num_indices= indices_U.size+indices_V.size+indices_P.size+1\n",
    "\n",
    "# Combine and sort the selected indices\n",
    "spa_indices = np.sort(np.concatenate([indices_U, indices_V, indices_P, indices_q.reshape(1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7ba7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = scipy.io.loadmat('TestRefSol_BDF2_Periodic_v2.mat')\n",
    "U_Ref = data1['U_Py']\n",
    "V_Ref = data1['V_Py']\n",
    "P_Ref = data1['P_Py']\n",
    "q_Ref = data1['q_Py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c53c5ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 4801)\n"
     ]
    }
   ],
   "source": [
    "# ntEnSF = 50\n",
    "ntEnSF = 100\n",
    "t0 = 0\n",
    "filtering_steps = ntEnSF\n",
    "timeTrue = np.linspace(0, 1, Nt+1)\n",
    "tEnSF = np.linspace(0, 1, filtering_steps+1)\n",
    "indices_time = np.searchsorted(timeTrue, tEnSF, side='left')\n",
    "\n",
    "\n",
    "state_ref = np.concatenate((U_Ref, V_Ref, P_Ref, q_Ref), axis=1)   \n",
    "\n",
    "state_timeextract = state_ref[indices_time, :].copy()\n",
    "\n",
    "state_EnSF = state_timeextract[:, spa_indices].copy()\n",
    "\n",
    "dtEnSF = (T - t0) / ntEnSF\n",
    "obs_sigma = 0.1\n",
    "\n",
    "eps_alpha = 0.05\n",
    "\n",
    "# ensemble size\n",
    "ensemble_size = 80\n",
    "ensemble_true = 1\n",
    "# forward Euler step\n",
    "euler_steps = 400\n",
    "def g_tau(t):\n",
    "    return 1-t\n",
    "\n",
    "U0_state = 2*np.random.randn(ensemble_size, Size_U)\n",
    "V0_state = 2*np.random.randn(ensemble_size, Size_V)\n",
    "P0_state = 2*np.random.randn(ensemble_size, Size_P)\n",
    "\n",
    "UV_state = np.concatenate((U0_state, V0_state, P0_state, np.full((ensemble_size, 1), 1)), axis=1)\n",
    "\n",
    "n_dim = Size_U+Size_V+Size_P+1\n",
    "rmse_all = []\n",
    "obs_save = []\n",
    "est_save = np.zeros((filtering_steps+1, n_dim))\n",
    "est_save[[0], :] += np.mean(UV_state, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcf2c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Noise omega_1\n",
    "SDE_Sigma_U = 0.001\n",
    "SDE_Sigma_V = 0.001\n",
    "SDE_Sigma_P = 0.001\n",
    "\n",
    "## Noise omega_1\n",
    "# SDE_Sigma_U = 0.1\n",
    "# SDE_Sigma_V = 0.1\n",
    "# SDE_Sigma_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50f6e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = scipy.io.loadmat('Permutation_Indices_EnSF_Per40_T100.mat')\n",
    "# data1 = scipy.io.loadmat('Permutation_Indices_EnSF_Per40.mat')\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perS_EnSF = data1['perS'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4837c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS_EnSF -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56eab309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "# Nt = T*50\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "# dt = T / Nt\n",
    "TTEnSF = np.arange(0, T + dtEnSF/2, dtEnSF)\n",
    "\n",
    "alpha_EnSFBE = 1 / dtEnSF   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha_EnSFBE * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A_EnSFBE = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA_EnSFBE = A_EnSFBE.diagonal()\n",
    "D_EnSFBE = diags(dA_EnSFBE, 0, shape=A_EnSFBE.shape, format='csr')\n",
    "E_EnSFBE = D_EnSFBE - A_EnSFBE\n",
    "Di_EnSFBE = diags(1.0 / dA_EnSFBE, 0, shape=A_EnSFBE.shape, format='csr')\n",
    "S_EnSFBE = B.dot(Di_EnSFBE.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perS_EnSF, perS_EnSF)\n",
    "S_perm = S_EnSFBE[rowsS, colsS].toarray()\n",
    "SS_EnSFBE = np.linalg.cholesky(S_perm).T\n",
    "SS_EnSFBEt = SS_EnSFBE.T\n",
    "DiE_EnSFBE = Di_EnSFBE.dot(E_EnSFBE)\n",
    "BDiE_EnSFBE = B.dot(DiE_EnSFBE)\n",
    "DiB_EnSFBEt = Di_EnSFBE.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "# U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "# V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "q_batch = np.full((ensemble_size,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d37ebf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS_EnSFnew = perS_EnSF.astype(int)\n",
    "\n",
    "perS_EnSFnew = np.squeeze(perS_EnSFnew, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e29535d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_U = np.stack([(Xu.T).reshape(-1), (Yu.T).reshape(-1)], axis=1)\n",
    "grid_V = np.stack([(Xv.T).reshape(-1), (Yv.T).reshape(-1)], axis=1)\n",
    "grid_P = np.stack([(Xp.T).reshape(-1), (Yp.T).reshape(-1)], axis=1)\n",
    "\n",
    "grid_total = np.vstack((grid_U, grid_V, grid_P))\n",
    "obs_xy    = grid_total[spa_indices[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dab8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(filtering_steps):\n",
    "    print(f'step={i}:')\n",
    "    t1 = time.time()    \n",
    "    \n",
    "#     obs = state_EnSF[[i+1], :].copy()\n",
    "    state_scale = state_EnSF[[i+1], :].copy()\n",
    "    \n",
    "    indob_scale0 = np.nonzero(((-1e-1 <= state_scale) & (state_scale < -1e-2)) |\n",
    "                              ((1e-2 <= state_scale) & (state_scale < 1e-1)))[1]\n",
    "    \n",
    "    indob_scale1 = np.nonzero(((-1e-2 <= state_scale) & (state_scale < -1e-3)) |\n",
    "                              ((1e-3 <= state_scale) & (state_scale < 1e-2)))[1]\n",
    "    \n",
    "    indob_scale2 = np.nonzero(((-1e-3 <= state_scale) & (state_scale < -1e-4)) |\n",
    "                              ((1e-4 <= state_scale) & (state_scale < 1e-3)))[1]\n",
    "\n",
    "    indob_scale3 = np.nonzero(((-1e-4 <= state_scale) & (state_scale < -1e-5)) |\n",
    "                              ((1e-5 <= state_scale) & (state_scale < 1e-4)))[1]\n",
    "\n",
    "    indob_scale4 = np.nonzero(((-1e-5 <= state_scale) & (state_scale < -1e-6)) |\n",
    "                              ((1e-6 <= state_scale) & (state_scale < 1e-5)))[1]\n",
    "    indob_scale5 = np.nonzero(((-1e-6 <= state_scale) & (state_scale < -1e-7)) |\n",
    "                              ((1e-7 <= state_scale) & (state_scale < 1e-6)))[1]\n",
    "    \n",
    "    indob_scale6 = np.nonzero(((-1e-12 <= state_scale) & (state_scale < -1e-13)) |\n",
    "                              ((1e-13 <= state_scale) & (state_scale < 1e-12)))[1]\n",
    "\n",
    "    indob_scale7 = np.nonzero(((-1e-13 <= state_scale) & (state_scale < -1e-14)) |\n",
    "                              ((1e-14 <= state_scale) & (state_scale < 1e-13)))[1]\n",
    "    \n",
    "    indob_scale8 = np.nonzero(((-1e-14 <= state_scale) & (state_scale < -1e-15)) |\n",
    "                              ((1e-15 <= state_scale) & (state_scale < 1e-14)))[1]\n",
    "    \n",
    "    indob_scale9 = np.nonzero(((-1e-15 <= state_scale) & (state_scale < -1e-16)) |\n",
    "                              ((1e-16 <= state_scale) & (state_scale < 1e-15)))[1]\n",
    "\n",
    "    indob_scale10 = np.nonzero(((-1e-16 <= state_scale) & (state_scale < -1e-17)) |\n",
    "                              ((1e-17 <= state_scale) & (state_scale < 1e-16)))[1]\n",
    "    indob_scale11 = np.nonzero(((-1e-17 <= state_scale) & (state_scale < 0)) |\n",
    "                              ((0 <= state_scale) & (state_scale < 1e-17)))[1]\n",
    "    \n",
    "    state_scale[:, indob_scale0] *= 1e1\n",
    "    state_scale[:, indob_scale1] *= 1e2\n",
    "    state_scale[:, indob_scale2] *= 1e3\n",
    "    state_scale[:, indob_scale3] *= 1e4\n",
    "    state_scale[:, indob_scale4] *= 1e5\n",
    "    state_scale[:, indob_scale5] *= 1e6\n",
    "    state_scale[:, indob_scale6] *= 1e12\n",
    "    state_scale[:, indob_scale7] *= 1e13\n",
    "    state_scale[:, indob_scale8] *= 1e14\n",
    "    state_scale[:, indob_scale9] *= 1e15\n",
    "    state_scale[:, indob_scale10] *= 1e16\n",
    "    state_scale[:, indob_scale11] *= 1e17\n",
    "    \n",
    "    obs = np.arctan(state_scale.copy())\n",
    "    obs += np.random.randn(*state_EnSF[[i+1], :].shape) * obs_sigma\n",
    "\n",
    "#     def score_likelihood(xt, t, C):\n",
    "#         # obs: (d)\n",
    "#         # xt: (ensemble, d)\n",
    "# #         A = -(xt - obs) / obs_sigma**2\n",
    "# #         score_x = A.copy()\n",
    "# #         score_x[:, idA_sub] =\\\n",
    "# #             -(np.arctan(xt[:, idA_sub]) - obs[:, idA_sub]) / obs_sigma**2 * (1. / (1 + xt[:, idA_sub]**2))\n",
    "#         score_x = -(np.arctan(xt) - obs)/obs_sigma**2 * (1./(1+xt**2))\n",
    "#         tau = g_tau(t)\n",
    "#         return tau * score_x / C\n",
    "       \n",
    "    U_stack = (U0_state.T).copy()\n",
    "    V_stack = (V0_state.T).copy()\n",
    "    \n",
    "    U_stack = U_stack.reshape(mU0, nU0, ensemble_size, order = 'F')\n",
    "    V_stack = V_stack.reshape(mV0, nV0, ensemble_size, order = 'F')\n",
    "    \n",
    "    U_new, V_new, P_new, q_new, egy_new, egy_theta_new,_ = \\\n",
    "            NS_Per.NS_BE_1step_Periodic_Vectorized(hx, hy, dtEnSF, TTEnSF[i+1], U_stack, V_stack, q_batch, Xu, Yu, Xv, Yv,\\\n",
    "                                                   mu, theta, opt, opt_UgradU, DiE_EnSFBE, BDiE_EnSFBE, DiB_EnSFBEt,\\\n",
    "                                                   Di_EnSFBE, B, Bt, perS_EnSFnew, SS_EnSFBE, SS_EnSFBEt, Nx, Ny, sU,\\\n",
    "                                                   alpha_EnSFBE, A1, B1)\n",
    "    \n",
    "    U_new_reshape = U_new.reshape(mU0*nU0, ensemble_size, order ='F')  \n",
    "    V_new_reshape = V_new.reshape(mV0*nV0, ensemble_size, order ='F')\n",
    "    P_new_reshape = P_new.reshape(mP0*nP0, ensemble_size, order ='F')\n",
    "    q_new_reshape = q_new.reshape(1, ensemble_size)\n",
    "    \n",
    "    # q_batch = q_new.copy()\n",
    "    x_state = np.concatenate((U_new_reshape, V_new_reshape, P_new_reshape, q_new_reshape))\n",
    "    \n",
    "    noiseU = np.sqrt(dtEnSF) * SDE_Sigma_U * np.random.randn(*U_new_reshape.shape)\n",
    "    noiseV = np.sqrt(dtEnSF) * SDE_Sigma_V * np.random.randn(*V_new_reshape.shape)\n",
    "    noiseP = np.sqrt(dtEnSF) * SDE_Sigma_P * np.random.randn(*P_new_reshape.shape)\n",
    "\n",
    "    noise = np.concatenate((noiseU, noiseV, noiseP, np.zeros((1, ensemble_size))))\n",
    "    \n",
    "    x_state += noise\n",
    "    x_state = x_state.T\n",
    "    \n",
    "    x0_EnSF = x_state[:, spa_indices].copy()\n",
    "    \n",
    "    R = obs_sigma**2 * np.eye(spa_indices.shape[0])\n",
    "    \n",
    "    indx_scale0 = np.argwhere(((-1e-1<=x0_EnSF) & (x0_EnSF<-1e-2)) | ((1e-2<=x0_EnSF) & (x0_EnSF<1e-1)))\n",
    "    indx_scale1 = np.argwhere(((-1e-2<=x0_EnSF) & (x0_EnSF<-1e-3)) | ((1e-3<=x0_EnSF) & (x0_EnSF<1e-2)))\n",
    "    indx_scale2 = np.argwhere(((-1e-3<=x0_EnSF) & (x0_EnSF<-1e-4)) | ((1e-4<=x0_EnSF) & (x0_EnSF<1e-3)))\n",
    "    indx_scale3 = np.argwhere(((-1e-4<=x0_EnSF) & (x0_EnSF<-1e-5)) | ((1e-5<=x0_EnSF) & (x0_EnSF<1e-4)))\n",
    "    indx_scale4 = np.argwhere(((-1e-5<=x0_EnSF) & (x0_EnSF<-1e-6)) | ((1e-6<=x0_EnSF) & (x0_EnSF<1e-5)))\n",
    "    indx_scale5 = np.argwhere(((-1e-6<=x0_EnSF) & (x0_EnSF<-1e-7)) | ((1e-7<=x0_EnSF) & (x0_EnSF<1e-6)))\n",
    "    indx_scale6 = np.argwhere(((-1e-12<=x0_EnSF) & (x0_EnSF<-1e-13)) | ((1e-13<=x0_EnSF) & (x0_EnSF<1e-12)))\n",
    "    indx_scale7 = np.argwhere(((-1e-13<=x0_EnSF) & (x0_EnSF<-1e-14)) | ((1e-14<=x0_EnSF) & (x0_EnSF<1e-13)))\n",
    "    indx_scale8 = np.argwhere(((-1e-14<=x0_EnSF) & (x0_EnSF<-1e-15)) | ((1e-15<=x0_EnSF) & (x0_EnSF<1e-14)))\n",
    "    indx_scale9 = np.argwhere(((-1e-15<=x0_EnSF) & (x0_EnSF<-1e-16)) | ((1e-16<=x0_EnSF) & (x0_EnSF<1e-15)))\n",
    "    indx_scale10 = np.argwhere(((-1e-16<=x0_EnSF) & (x0_EnSF<-1e-17)) | ((1e-17<=x0_EnSF) & (x0_EnSF<1e-16)))\n",
    "    indx_scale11 = np.argwhere(((-1e-17<=x0_EnSF) & (x0_EnSF<0)) | ((0<=x0_EnSF) & (x0_EnSF<1e-17)))\n",
    "\n",
    "    x0_EnSF[indx_scale0[:, 0], indx_scale0[:, 1]] *= 1e1\n",
    "    x0_EnSF[indx_scale1[:, 0], indx_scale1[:, 1]] *= 1e2\n",
    "    x0_EnSF[indx_scale2[:, 0], indx_scale2[:, 1]] *= 1e3\n",
    "    x0_EnSF[indx_scale3[:, 0], indx_scale3[:, 1]] *= 1e4\n",
    "    x0_EnSF[indx_scale4[:, 0], indx_scale4[:, 1]] *= 1e5\n",
    "    x0_EnSF[indx_scale5[:, 0], indx_scale5[:, 1]] *= 1e6\n",
    "    x0_EnSF[indx_scale6[:, 0], indx_scale6[:, 1]] *= 1e12\n",
    "    x0_EnSF[indx_scale7[:, 0], indx_scale7[:, 1]] *= 1e13\n",
    "    x0_EnSF[indx_scale8[:, 0], indx_scale8[:, 1]] *= 1e14\n",
    "    x0_EnSF[indx_scale9[:, 0], indx_scale9[:, 1]] *= 1e15\n",
    "    x0_EnSF[indx_scale10[:, 0], indx_scale10[:, 1]] *= 1e16\n",
    "    x0_EnSF[indx_scale11[:, 0], indx_scale11[:, 1]] *= 1e17\n",
    "    \n",
    "    x_state[:, spa_indices] = x0_EnSF.copy()\n",
    "#     Xb_LETKF = x_state[:, spa_indices].clone()\n",
    "    Xb_LETKF = x_state.copy()\n",
    "    Xb = Xb_LETKF.T\n",
    "    y  = (obs.copy()).T\n",
    "#     rho = 2\n",
    "    rho = 4\n",
    "    radius = 1\n",
    "    Xa_LETKF = LETKF_local(Xb, y, R, rho, Nx, Ny, spa_indices,  grid_total, obs_xy, radius)\n",
    "    x_scale = (Xa_LETKF.copy()).T\n",
    "    x0_EnSF = x_scale[:, spa_indices].copy()\n",
    "\n",
    "    x0_EnSF[:, indob_scale0] /= 1e1\n",
    "    x0_EnSF[:, indob_scale1] /= 1e2\n",
    "    x0_EnSF[:, indob_scale2] /= 1e3\n",
    "    x0_EnSF[:, indob_scale3] /= 1e4\n",
    "    x0_EnSF[:, indob_scale4] /= 1e5\n",
    "    x0_EnSF[:, indob_scale5] /= 1e6\n",
    "    x0_EnSF[:, indob_scale6] /= 1e12\n",
    "    x0_EnSF[:, indob_scale7] /= 1e13\n",
    "    x0_EnSF[:, indob_scale8] /= 1e14\n",
    "    x0_EnSF[:, indob_scale9] /= 1e15\n",
    "    x0_EnSF[:, indob_scale10] /= 1e16\n",
    "    x0_EnSF[:, indob_scale11] /= 1e17\n",
    "\n",
    "    x_scale[:, spa_indices] = x0_EnSF.copy()\n",
    "    x_state = x_scale.copy()\n",
    "    \n",
    "    x_state[:, np.arange(0, Size_U)] = np.clip(x_state[:, np.arange(0, Size_U)], -0.9, 0.9)\n",
    "    x_state[:, Size_U+np.arange(0, Size_V)] = np.clip(x_state[:, Size_U+np.arange(0, Size_V)], -0.9, 0.9)\n",
    "    x_state[:, Size_U+Size_V+np.arange(0, Size_P)] = np.clip(x_state[:, Size_U+Size_V+np.arange(0, Size_P)], -0.6, 0.6)\n",
    "    x_state[:, -1] = np.clip(x_state[:, -1], 0.8, 1.05)\n",
    "    \n",
    "    U0_state = x_state[:, :Size_U].copy()\n",
    "    V0_state = x_state[:, Size_U+np.arange(0, Size_V)].copy()\n",
    "    q_batch = x_state[:, -1].copy()\n",
    "    print(q_Ref[i+1])\n",
    "    # print(q_batch)\n",
    "    est_save[[i+1], :] += np.mean(x_state, axis=0)\n",
    "    print(est_save[i+1, -1])\n",
    "    # get rmse\n",
    "    rmse_temp = np.sqrt(np.mean((est_save[[i+1], :] - state_timeextract[[i+1], :])**2))\n",
    "\n",
    "    # get time\n",
    "    t2 = time.time()\n",
    "    print(f'\\t RMSE = {rmse_temp:.4f}')\n",
    "    print(f'\\t time = {t2 - t1:.4f}')\n",
    "\n",
    "    # save information\n",
    "    rmse_all.append(rmse_temp)\n",
    "\n",
    "    # check divergence\n",
    "    if rmse_temp > 1000:\n",
    "        print('diverge!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76c9863c-1f38-40a3-8554-b008dd23b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_EnSF = est_save[:, :Size_U]\n",
    "V_EnSF = est_save[:, Size_U+np.arange(0, Size_V)]\n",
    "P_EnSF = est_save[:, Size_U+Size_V+np.arange(0, Size_P)]\n",
    "q_EnSF = est_save[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "184732b4-9bf9-4e8c-b984-eb4abd648ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('ResultLETKF_Periodic_T100_70Obs_noise0001_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "                                               'q_EnSF': q_EnSF, 'rmse': rmse_all})\n",
    "\n",
    "# scipy.io.savemat('ResultLETKF_Periodic_T100_7Obs_noise01_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "#                                                'q_EnSF': q_EnSF, 'rmse': rmse_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f2e14-4a9e-4cec-872e-f43a379474a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
