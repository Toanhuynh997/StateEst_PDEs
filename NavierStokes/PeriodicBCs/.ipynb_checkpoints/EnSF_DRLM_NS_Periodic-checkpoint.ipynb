{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f17b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import eye, diags, block_diag, hstack\n",
    "from scipy.sparse.csgraph import reverse_cuthill_mckee\n",
    "from scipy.sparse.linalg import gmres\n",
    "# from scipy.sparse.csgraph import symmetrix_degree_order\n",
    "import importlib\n",
    "import time\n",
    "import NavierStokes_Periodic_Solver as NS_Per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1b4a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NavierStokes_Periodic_Solver' from 'D:\\\\GitHub\\\\StateEst_PDEs\\\\NavierStokes\\\\PeriodicBCs\\\\NavierStokes_Periodic_Solver.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(NS_Per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d75d6",
   "metadata": {},
   "source": [
    "# Reference solution using BDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af736e6",
   "metadata": {},
   "source": [
    "## Setting for 1 step BE: Run \"script_run_per\" with \"NS_bEuler_per\" solver and Nt=T*600 to get \"Permutation_Indices_RefSol_Per40.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a808aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('Permutation_Indices_RefSol_Per40.mat')\n",
    "\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perS = data['perS'].astype(np.float64)\n",
    "# perA = data['perA'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3930d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS -= 1\n",
    "# perA -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b34a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "Nt = T*600\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "dt = T / Nt\n",
    "TT = np.arange(0, T + dt/2, dt)\n",
    "\n",
    "alpha_BE = 1 / dt   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha_BE * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A_BE = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA_BE = A_BE.diagonal()\n",
    "D_BE = diags(dA_BE, 0, shape=A_BE.shape, format='csr')\n",
    "E_BE = D_BE - A_BE\n",
    "Di_BE = diags(1.0 / dA_BE, 0, shape=A_BE.shape, format='csr')\n",
    "S_BE = B.dot(Di_BE.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perS, perS)\n",
    "S_perm = S_BE[rowsS, colsS].toarray()\n",
    "SS_BE = np.linalg.cholesky(S_perm).T\n",
    "SS_BEt = SS_BE.T\n",
    "DiE_BE = Di_BE.dot(E_BE)\n",
    "BDiE_BE = B.dot(DiE_BE)\n",
    "DiB_BEt = Di_BE.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "q_batch = np.full((2,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f270fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "perSBE_new = perS.astype(int)\n",
    "\n",
    "perSBE_new = np.squeeze(perSBE_new, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2c743",
   "metadata": {},
   "source": [
    "## Setting for BDF2:Run \"script_run_per\" with \"NS_BDF_per\" solver and Nt=T*600 to get \"Permutation_Indices_RefSol_BDF2Per40.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf29140",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('Permutation_Indices_RefSol_BDF2Per40.mat')\n",
    "\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perBDFS = data['perS'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fbe73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perBDFS -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5bd323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "Nt = T*600\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "dt = T / Nt\n",
    "TT = np.arange(0, T + dt/2, dt)\n",
    "\n",
    "alpha = 1.5 / dt   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA = A.diagonal()\n",
    "D = diags(dA, 0, shape=A.shape, format='csr')\n",
    "E = D - A\n",
    "Di = diags(1.0 / dA, 0, shape=A.shape, format='csr')\n",
    "S = B.dot(Di.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perBDFS, perBDFS)\n",
    "S_perm = S[rowsS, colsS].toarray()\n",
    "SS = np.linalg.cholesky(S_perm).T\n",
    "SSt = SS.T\n",
    "DiE = Di.dot(E)\n",
    "BDiE = B.dot(DiE)\n",
    "DiBt = Di.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "# q_batch = np.full((2,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9a3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perBDFS_new = perBDFS.astype(int)\n",
    "\n",
    "perBDFS_new = np.squeeze(perBDFS_new, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e095e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mU0, nU0 = U0.shape\n",
    "mV0, nV0 = V0.shape\n",
    "mP0, nP0 = Xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32454e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_U = np.zeros((Nt+1, mU0*nU0))\n",
    "All_V = np.zeros((Nt+1, mV0*nV0))\n",
    "All_P = np.zeros((Nt+1, mP0*nP0))\n",
    "All_q = np.zeros((Nt+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2bad6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_U[0, :] += np.reshape(U0, mU0*nU0, order='F')\n",
    "All_V[0, :] += np.reshape(V0, mV0*nV0, order='F')\n",
    "All_q[0, :] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9907e4d-e363-4981-a619-f4c9063b85e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(All_U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930585c3",
   "metadata": {},
   "source": [
    "### 1 step BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e597088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = 1\n",
    "U = U0.copy()\n",
    "V = V0.copy()\n",
    "## nt = 1 here\n",
    "for k in range(1):\n",
    "    print(k)\n",
    "    U_new, V_new, P_new, q_new, egy_new, egy_theta_new,_ = \\\n",
    "            NS_Per.NS_BE_1step_Periodic(hx, hy, dt, TT[k+1], U, V, q0, Xu, Yu, Xv, Yv, mu, theta, opt, opt_UgradU,\\\n",
    "                                        DiE_BE, BDiE_BE, DiB_BEt, Di_BE, B, Bt, perSBE_new, SS_BE, SS_BEt, Nx, Ny,\\\n",
    "                                        sU, alpha_BE, A1, B1)\n",
    "    \n",
    "#     print(q_new)\n",
    "#     qq[k+1] = q_new\n",
    "    U = U_new.copy()\n",
    "    V = V_new.copy()\n",
    "    P = P_new.copy()\n",
    "    q0 = q_new.copy()\n",
    "    \n",
    "    All_U[1, :] += np.reshape(U, mU0*nU0, order='F')\n",
    "    All_V[1, :] += np.reshape(V, mV0*nV0, order='F')\n",
    "    All_P[1, :] += np.reshape(P, mP0*nP0, order='F')\n",
    "    All_q[1, :] += q_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f184733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_old_old = U0.copy()\n",
    "V_old_old = V0.copy()\n",
    "U_old = U_new.copy()\n",
    "V_old = V_new.copy()\n",
    "q_old = q_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bdb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq[1] = q_old\n",
    "q_old_old = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3bfc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(1, Nt):\n",
    "    print(kk)\n",
    "    U_new, V_new, P_new, q_new, _= \\\n",
    "                NS_Per.NS_BDF2_1step_periodic(hx, hy, dt, TT[kk+1], U_old_old, V_old_old, U_old, V_old,\\\n",
    "                                              q_old, q_old_old, Xu, Yu, Xv, Yv, mu, theta, opt, opt_UgradU,\\\n",
    "                                              DiE, BDiE, DiBt, Di, B, Bt, perBDFS_new, SS, SSt, Nx, Ny, sU, \\\n",
    "                                              alpha, A1, B1)\n",
    "        \n",
    "    ## Update\n",
    "    U_old_old = U_old.copy()\n",
    "    V_old_old = V_old.copy()\n",
    "    \n",
    "    U_old = U_new.copy()\n",
    "    V_old = V_new.copy()\n",
    "    \n",
    "    q_old_old = q_old\n",
    "    q_old = q_new\n",
    "    \n",
    "#     qq[kk+1] = q_new\n",
    "    \n",
    "    All_U[kk+1, :] += np.reshape(U_new, mU0*nU0, order='F')\n",
    "    All_V[kk+1, :] += np.reshape(V_new, mV0*nV0, order='F')\n",
    "    All_P[kk+1, :] += np.reshape(P_new, mP0*nP0, order='F')\n",
    "    All_q[kk+1, :] += q_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e744e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Ref = All_U.copy()\n",
    "V_Ref = All_V.copy()\n",
    "P_Ref = All_P.copy()\n",
    "q_Ref = All_q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "197fc6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('TestRefSol_BDF2_Periodic_v1.mat', \\\n",
    "                 {'U_Py':U_Ref, 'V_Py':V_Ref, 'P_Py':P_Ref, 'q_Py':q_Ref})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dcaae",
   "metadata": {},
   "source": [
    "# Performing EnSF with BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46b56278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_alpha(t):\n",
    "    # conditional information\n",
    "    # alpha_t(0) = 1\n",
    "    # alpha_t(1) = esp_alpha \\approx 0\n",
    "    return 1 - (1-eps_alpha)*t\n",
    "\n",
    "\n",
    "def cond_sigma_sq(t):\n",
    "    # conditional sigma^2\n",
    "    # sigma2_t(0) = 0\n",
    "    # sigma2_t(1) = 1\n",
    "    # sigma(t) = t\n",
    "    return t\n",
    "\n",
    "def cond_sigma_sq(t):\n",
    "    # conditional sigma^2\n",
    "    # sigma2_t(0) = 0\n",
    "    # sigma2_t(1) = 1\n",
    "    # sigma(t) = t\n",
    "    return t\n",
    "\n",
    "def f(t):\n",
    "    # f=d_(log_alpha)/dt\n",
    "    alpha_t = cond_alpha(t)\n",
    "    f_t = -(1-eps_alpha) / alpha_t\n",
    "    return f_t\n",
    "\n",
    "def g_sq(t):\n",
    "    # g = d(sigma_t^2)/dt -2f sigma_t^2\n",
    "    d_sigma_sq_dt = 1\n",
    "    g2 = d_sigma_sq_dt - 2*f(t)*cond_sigma_sq(t)\n",
    "    return g2\n",
    "\n",
    "def g(t):\n",
    "    return np.sqrt(g_sq(t))\n",
    "\n",
    "def reverse_SDE(x0, time_steps, C, score_likelihood=None, drift_fun=f, \\\n",
    "                diffuse_fun=g, alpha_fun=cond_alpha, sigma2_fun=cond_sigma_sq, save_path=False):\n",
    "    # x_T: sample from standard Gaussian\n",
    "    # x_0: target distribution to sample from\n",
    "\n",
    "    # reverse SDE sampling process\n",
    "    # N1 = x_T.shape[0]\n",
    "    # N2 = x0.shape[0]\n",
    "    # d = x_T.shape[1]\n",
    "\n",
    "    # Generate the time mesh\n",
    "    dt = 1.0/time_steps\n",
    "\n",
    "    # Initialization\n",
    "    xt = np.random.randn(x0.shape[0], x0.shape[1])\n",
    "    t = 1.0\n",
    "    \n",
    "    path_all = []\n",
    "    t_vec = []\n",
    "    \n",
    "    # define storage\n",
    "    if save_path:\n",
    "        path_all.append(xt.copy())\n",
    "        t_vec.append(t)\n",
    "    \n",
    "    # forward Euler sampling\n",
    "    for i in range(time_steps):\n",
    "        # prior score evaluation\n",
    "        alpha_t = alpha_fun(t)\n",
    "        sigma2_t = sigma2_fun(t)\n",
    "\n",
    "\n",
    "        # Evaluate the diffusion term\n",
    "        diffuse = diffuse_fun(t)\n",
    "\n",
    "        # Evaluate the drift term\n",
    "        # drift = drift_fun(t)*xt - diffuse**2 * score_eval\n",
    "\n",
    "        # Update\n",
    "        if score_likelihood is not None:\n",
    "#             zt = score_likelihood(xt, t)\n",
    "#             print(zt.size())\n",
    "            xt += -dt*(drift_fun(t)*xt+diffuse**2*((xt-alpha_t*x0)/sigma2_t)-\\\n",
    "                       diffuse**2*score_likelihood(xt, t, C)) +np.sqrt(dt)*diffuse*np.random.randn(*xt.shape)\n",
    "    \n",
    "        else:\n",
    "            xt += -dt*(drift_fun(t)*xt+diffuse**2*((xt-alpha_t*x0)/sigma2_t))+np.sqrt(dt)*diffuse*np.random.randn(*xt.shape)\n",
    "        \n",
    "#         xt = xt.to(torch.float64)\n",
    "        # Store the state in the path\n",
    "        if save_path:\n",
    "            path_all.append(xt.copy())\n",
    "            t_vec.append(t)\n",
    "\n",
    "        # update time\n",
    "        t = t - dt\n",
    "\n",
    "    if save_path:\n",
    "        return path_all, t_vec\n",
    "    else:\n",
    "        return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9355f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mU, nU = U_Ref.shape\n",
    "# mV, nV = V_Ref.shape\n",
    "# mP, nP = P_Ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6ba5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size_U = mU0*nU0\n",
    "Size_V = mV0*nV0\n",
    "Size_P = mP0*nP0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f4d7cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "# ## 100% arctangent observation\n",
    "indices_U = np.random.permutation(Size_U)[:int(1 * Size_U)]\n",
    "indices_V = np.random.permutation(Size_V)[:int(1 * Size_V)] + Size_U\n",
    "indices_P = np.random.permutation(Size_P)[:int(1 * Size_P)] + Size_U + Size_V\n",
    "indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "\n",
    "\n",
    "## 70% arctangent observation\n",
    "# indices_U = np.random.permutation(Size_U)[:int(0.7 * Size_U)]\n",
    "# indices_V = np.random.permutation(Size_V)[:int(0.7 * Size_V)] + Size_U\n",
    "# indices_P = np.random.permutation(Size_P)[:int(0.7 * Size_P)] + Size_U + Size_V\n",
    "# indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "\n",
    "\n",
    "## 7% arctangent observation\n",
    "# indices_U = np.random.permutation(Size_U)[:int(0.07* Size_U)]\n",
    "# indices_V = np.random.permutation(Size_V)[:int(0.07* Size_V)] + Size_U\n",
    "# indices_P = np.random.permutation(Size_P)[:int(0.07* Size_P)] + Size_U + Size_V\n",
    "# indices_q = np.array(Size_U+Size_V+Size_P)\n",
    "num_indices= indices_U.size+indices_V.size+indices_P.size+1\n",
    "\n",
    "# Combine and sort the selected indices\n",
    "spa_indices = np.sort(np.concatenate([indices_U, indices_V, indices_P, indices_q.reshape(1)]))\n",
    "print(num_indices)\n",
    "print(indices_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d1d17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = scipy.io.loadmat('TestRefSol_BDF2_Periodic_v1.mat')\n",
    "U_Ref = data1['U_Py']\n",
    "V_Ref = data1['V_Py']\n",
    "P_Ref = data1['P_Py']\n",
    "q_Ref = data1['q_Py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de659e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 4801)\n"
     ]
    }
   ],
   "source": [
    "# ntEnSF = 50\n",
    "ntEnSF = 100\n",
    "t0 = 0\n",
    "filtering_steps = ntEnSF\n",
    "timeTrue = np.linspace(0, 1, Nt+1)\n",
    "tEnSF = np.linspace(0, 1, filtering_steps+1)\n",
    "indices_time = np.searchsorted(timeTrue, tEnSF, side='left')\n",
    "\n",
    "\n",
    "state_ref = np.concatenate((U_Ref, V_Ref, P_Ref, q_Ref), axis=1)   \n",
    "\n",
    "print(state_ref.shape)\n",
    "state_timeextract = state_ref[indices_time, :].copy()\n",
    "\n",
    "state_EnSF = state_timeextract[:, spa_indices].copy()\n",
    "\n",
    "dtEnSF = (T - t0) / ntEnSF\n",
    "obs_sigma = 0.1\n",
    "\n",
    "eps_alpha = 0.05\n",
    "\n",
    "# ensemble size\n",
    "ensemble_size = 80\n",
    "ensemble_true = 1\n",
    "# forward Euler step\n",
    "euler_steps = 400\n",
    "def g_tau(t):\n",
    "    return 1-t\n",
    "\n",
    "U0_state = 2*np.random.randn(ensemble_size, Size_U)\n",
    "V0_state = 2*np.random.randn(ensemble_size, Size_V)\n",
    "P0_state = 2*np.random.randn(ensemble_size, Size_P)\n",
    "\n",
    "UV_state = np.concatenate((U0_state, V0_state, P0_state, np.full((ensemble_size, 1), 1)), axis=1)\n",
    "\n",
    "n_dim = Size_U+Size_V+Size_P+1\n",
    "rmse_all = []\n",
    "obs_save = []\n",
    "est_save = np.zeros((filtering_steps+1, n_dim))\n",
    "est_save[[0], :] += np.mean(UV_state, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bf7ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Noise omega_1\n",
    "SDE_Sigma_U = 0.001\n",
    "SDE_Sigma_V = 0.001\n",
    "SDE_Sigma_P = 0.001\n",
    "\n",
    "## Noise omega_2\n",
    "# SDE_Sigma_U = 0.1\n",
    "# SDE_Sigma_V = 0.1\n",
    "# SDE_Sigma_P = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4eb9",
   "metadata": {},
   "source": [
    "## Run \"script_run_per\" with \"NS_bEuler_per\" solver and Nt = T*100 to get \"Permutation_Indices_EnSF_Per40_T100.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bef7de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = scipy.io.loadmat('Permutation_Indices_EnSF_Per40_T100.mat')\n",
    "# data1 = scipy.io.loadmat('Permutation_Indices_EnSF_Per40.mat')\n",
    "# Convert MATLAB arrays to NumPy arrays and cast to float64.\n",
    "perS_EnSF = data1['perS'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "23b3aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS_EnSF -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96d05c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following helper functions are defined:\n",
    "# -------------------------------\n",
    "# Domain discretization and time setup\n",
    "xa = 0 \n",
    "xb = 1\n",
    "ya = 0 \n",
    "yb = 1 \n",
    "T = 1\n",
    "\n",
    "mu = 0.001\n",
    "# n = 8; Nx = 32*n; Ny = Nx; Nt = 8*n;\n",
    "\n",
    "theta = 5\n",
    "Nx = 40\n",
    "Ny = Nx\n",
    "# Nt = T*50\n",
    "\n",
    "hx = (xb - xa) / Nx\n",
    "hy = (yb - ya) / Ny\n",
    "# Create grid points: MATLAB: x = xa:hx:xb, y = ya:hy:yb\n",
    "x = np.arange(xa, xb + hx/2, hx)  # adding hx/2 ensures xb is included\n",
    "y = np.arange(ya, yb + hy/2, hy)\n",
    "xmid = NS_Per.avg(x)\n",
    "ymid = NS_Per.avg(y)\n",
    "# dt = T / Nt\n",
    "TTEnSF = np.arange(0, T + dtEnSF/2, dtEnSF)\n",
    "\n",
    "alpha_EnSFBE = 1 / dtEnSF   # alpha*u - mu*Delta(u) + grad(p) = f\n",
    "opt_UgradU = 1   # 1: original, 2: MIT (not good)\n",
    "opt = 2\n",
    "# -------------------------------\n",
    "# Construct matrices A and B\n",
    "\n",
    "# Sizes:\n",
    "sU = (Nx) * Ny       # for U-velocity unknowns\n",
    "sV = sU       # for V-velocity unknowns\n",
    "sP = sU             # for pressure\n",
    "\n",
    "\n",
    "# --- Build matrix A ---\n",
    "A0  = NS_Per.DiscreteLaplace(Nx,hx)\n",
    "B0  = NS_Per.DiscreteLaplace(Ny,hy)\n",
    "\n",
    "A_u = alpha_EnSFBE * sp.eye(sU) - mu * (sp.kron(sp.eye(Ny), A0) + sp.kron(B0, sp.eye(Nx)))\n",
    "A_v = A_u.copy()\n",
    "\n",
    "A_EnSFBE = block_diag((A_u, A_v), format='csr')\n",
    "\n",
    "# # --- Construct matrix B ---\n",
    "\n",
    "A1 = NS_Per.DiscreteGrad(Nx,hx)         # P_x = A1*P\n",
    "B1 = NS_Per.DiscreteGrad(Ny,hy)         # P_y = P*B1'\n",
    "\n",
    "B2 = sp.kron(sp.eye(Ny), A1.T)\n",
    "B3 = sp.kron(B1.T, sp.eye(Nx))\n",
    "B = sp.hstack([B2, B3], format='csr')\n",
    "\n",
    "B = B[1:, :]\n",
    "Bt = B.transpose().tocsr()\n",
    "\n",
    "# # --- Prepare matrices for the pressure correction ---\n",
    "dA_EnSFBE = A_EnSFBE.diagonal()\n",
    "D_EnSFBE = diags(dA_EnSFBE, 0, shape=A_EnSFBE.shape, format='csr')\n",
    "E_EnSFBE = D_EnSFBE - A_EnSFBE\n",
    "Di_EnSFBE = diags(1.0 / dA_EnSFBE, 0, shape=A_EnSFBE.shape, format='csr')\n",
    "S_EnSFBE = B.dot(Di_EnSFBE.dot(Bt))\n",
    "# # perS = reverse_cuthill_mckee(S)\n",
    "# # S_perm = S[perS, :][:, perS].toarray()\n",
    "\n",
    "rowsS, colsS = np.meshgrid(perS_EnSF, perS_EnSF)\n",
    "S_perm = S_EnSFBE[rowsS, colsS].toarray()\n",
    "SS_EnSFBE = np.linalg.cholesky(S_perm).T\n",
    "SS_EnSFBEt = SS_EnSFBE.T\n",
    "DiE_EnSFBE = Di_EnSFBE.dot(E_EnSFBE)\n",
    "BDiE_EnSFBE = B.dot(DiE_EnSFBE)\n",
    "DiB_EnSFBEt = Di_EnSFBE.dot(Bt)\n",
    "\n",
    "## Create mesh\n",
    "Yu, Xu = np.meshgrid(ymid, x[0:-1], indexing='xy')\n",
    "\n",
    "Yv, Xv = np.meshgrid(y[0:-1], xmid, indexing='xy')\n",
    "\n",
    "Yp, Xp = np.meshgrid(ymid, xmid, indexing='xy')\n",
    "\n",
    "# Initialize velocity fields using your exact solution functions.\n",
    "# U0 = NS_Per.u_init(Xu, Yu, opt)  # dimensions should match (len(x[1:-1]) x len(ymid))\n",
    "# V0 = NS_Per.v_init(Xv, Yv, opt)\n",
    "\n",
    "# Initialize pressure-related quantities.\n",
    "q = 1\n",
    "\n",
    "q_batch = np.full((ensemble_size,), q)\n",
    "# qq = np.zeros(Nt+1)\n",
    "# qq[0] = q\n",
    "\n",
    "# egy = np.zeros(Nt + 1)\n",
    "# egy_theta = egy.copy()\n",
    "# egy[0] = 0.5 * hx * hy * (NS_Per.inner(U0, U0) + NS_Per.inner(V0, V0))\n",
    "# egy_theta[0] = egy[0]+theta*(q**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75768467",
   "metadata": {},
   "outputs": [],
   "source": [
    "perS_EnSFnew = perS_EnSF.astype(int)\n",
    "\n",
    "perS_EnSFnew = np.squeeze(perS_EnSFnew, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca036fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(filtering_steps):\n",
    "    print(f'step={i}:')\n",
    "    t1 = time.time()    \n",
    "    \n",
    "#     obs = state_EnSF[[i+1], :].copy()\n",
    "    state_scale = state_EnSF[[i+1], :].copy()\n",
    "    \n",
    "    indob_scale0 = np.nonzero(((-1e-1 <= state_scale) & (state_scale < -1e-2)) |\n",
    "                              ((1e-2 <= state_scale) & (state_scale < 1e-1)))[1]\n",
    "    \n",
    "    indob_scale1 = np.nonzero(((-1e-2 <= state_scale) & (state_scale < -1e-3)) |\n",
    "                              ((1e-3 <= state_scale) & (state_scale < 1e-2)))[1]\n",
    "    \n",
    "    indob_scale2 = np.nonzero(((-1e-3 <= state_scale) & (state_scale < -1e-4)) |\n",
    "                              ((1e-4 <= state_scale) & (state_scale < 1e-3)))[1]\n",
    "\n",
    "    indob_scale3 = np.nonzero(((-1e-4 <= state_scale) & (state_scale < -1e-5)) |\n",
    "                              ((1e-5 <= state_scale) & (state_scale < 1e-4)))[1]\n",
    "\n",
    "    indob_scale4 = np.nonzero(((-1e-5 <= state_scale) & (state_scale < -1e-6)) |\n",
    "                              ((1e-6 <= state_scale) & (state_scale < 1e-5)))[1]\n",
    "\n",
    "    indob_scale5 = np.nonzero(((-1e-12 <= state_scale) & (state_scale < -1e-13)) |\n",
    "                              ((1e-13 <= state_scale) & (state_scale < 1e-12)))[1]\n",
    "\n",
    "    indob_scale6 = np.nonzero(((-1e-13 <= state_scale) & (state_scale < -1e-14)) |\n",
    "                              ((1e-14 <= state_scale) & (state_scale < 1e-13)))[1]\n",
    "    \n",
    "    indob_scale7 = np.nonzero(((-1e-14 <= state_scale) & (state_scale < -1e-15)) |\n",
    "                              ((1e-15 <= state_scale) & (state_scale < 1e-14)))[1]\n",
    "    \n",
    "    indob_scale8 = np.nonzero(((-1e-15 <= state_scale) & (state_scale < -1e-16)) |\n",
    "                              ((1e-16 <= state_scale) & (state_scale < 1e-15)))[1]\n",
    "\n",
    "    indob_scale9 = np.nonzero(((-1e-16 <= state_scale) & (state_scale < -1e-17)) |\n",
    "                              ((1e-17 <= state_scale) & (state_scale < 1e-16)))[1]\n",
    "    \n",
    "    # state_scale[:, indob_scale1] *= 5e1\n",
    "    state_scale[:, indob_scale1] *= 1e2\n",
    "    state_scale[:, indob_scale2] *= 1e3\n",
    "    state_scale[:, indob_scale3] *= 1e4\n",
    "    state_scale[:, indob_scale4] *= 1e5\n",
    "    state_scale[:, indob_scale5] *= 1e12\n",
    "    state_scale[:, indob_scale6] *= 1e13\n",
    "    state_scale[:, indob_scale7] *= 1e14\n",
    "    state_scale[:, indob_scale8] *= 1e15\n",
    "    state_scale[:, indob_scale9] *= 1e16\n",
    "    \n",
    "    obs = np.arctan(state_scale.copy())\n",
    "    obs += np.random.randn(*state_EnSF[[i+1], :].shape) * obs_sigma\n",
    "\n",
    "    def score_likelihood(xt, t, C):\n",
    "        # obs: (d)\n",
    "        # xt: (ensemble, d)\n",
    "#         A = -(xt - obs) / obs_sigma**2\n",
    "#         score_x = A.copy()\n",
    "#         score_x[:, idA_sub] =\\\n",
    "#             -(np.arctan(xt[:, idA_sub]) - obs[:, idA_sub]) / obs_sigma**2 * (1. / (1 + xt[:, idA_sub]**2))\n",
    "        score_x = -(np.arctan(xt) - obs)/obs_sigma**2 * (1./(1+xt**2))\n",
    "        tau = g_tau(t)\n",
    "        return tau * score_x / C\n",
    "       \n",
    "    U_stack = (U0_state.T).copy()\n",
    "    V_stack = (V0_state.T).copy()\n",
    "    \n",
    "    U_stack = U_stack.reshape(mU0, nU0, ensemble_size, order = 'F')\n",
    "    V_stack = V_stack.reshape(mV0, nV0, ensemble_size, order = 'F')\n",
    "    \n",
    "    U_new, V_new, P_new, q_new, egy_new, egy_theta_new,_ = \\\n",
    "            NS_Per.NS_BE_1step_Periodic_Vectorized(hx, hy, dtEnSF, TTEnSF[i+1], U_stack, V_stack, q_batch, Xu, Yu, Xv, Yv,\\\n",
    "                                                   mu, theta, opt, opt_UgradU, DiE_EnSFBE, BDiE_EnSFBE, DiB_EnSFBEt,\\\n",
    "                                                   Di_EnSFBE, B, Bt, perS_EnSFnew, SS_EnSFBE, SS_EnSFBEt, Nx, Ny, sU,\\\n",
    "                                                   alpha_EnSFBE, A1, B1)\n",
    "    \n",
    "    U_new_reshape = U_new.reshape(mU0*nU0, ensemble_size, order ='F')  \n",
    "    V_new_reshape = V_new.reshape(mV0*nV0, ensemble_size, order ='F')\n",
    "    P_new_reshape = P_new.reshape(mP0*nP0, ensemble_size, order ='F')\n",
    "    q_new_reshape = q_new.reshape(1, ensemble_size)\n",
    "    \n",
    "    # q_batch = q_new.copy()\n",
    "    x_state = np.concatenate((U_new_reshape, V_new_reshape, P_new_reshape, q_new_reshape))\n",
    "    \n",
    "    noiseU = np.sqrt(dtEnSF) * SDE_Sigma_U * np.random.randn(*U_new_reshape.shape)\n",
    "    noiseV = np.sqrt(dtEnSF) * SDE_Sigma_V * np.random.randn(*V_new_reshape.shape)\n",
    "    noiseP = np.sqrt(dtEnSF) * SDE_Sigma_P * np.random.randn(*P_new_reshape.shape)\n",
    "\n",
    "    noise = np.concatenate((noiseU, noiseV, noiseP, np.zeros((1, ensemble_size))))\n",
    "    \n",
    "    x_state += noise\n",
    "    x_state = x_state.T\n",
    "    \n",
    "    x0_EnSF = x_state[:, spa_indices].copy()\n",
    "\n",
    "    for l in range(7):      \n",
    "        indx_scale0 = np.argwhere(((-1e-1<=x0_EnSF) & (x0_EnSF<-1e-2)) | ((1e-2<=x0_EnSF) & (x0_EnSF<1e-1)))\n",
    "        indx_scale1 = np.argwhere(((-1e-2<=x0_EnSF) & (x0_EnSF<-1e-3)) | ((1e-3<=x0_EnSF) & (x0_EnSF<1e-2)))\n",
    "        indx_scale2 = np.argwhere(((-1e-3<=x0_EnSF) & (x0_EnSF<-1e-4)) | ((1e-4<=x0_EnSF) & (x0_EnSF<1e-3)))\n",
    "        indx_scale3 = np.argwhere(((-1e-4<=x0_EnSF) & (x0_EnSF<-1e-5)) | ((1e-5<=x0_EnSF) & (x0_EnSF<1e-4)))\n",
    "        indx_scale4 = np.argwhere(((-1e-5<=x0_EnSF) & (x0_EnSF<-1e-6)) | ((1e-6<=x0_EnSF) & (x0_EnSF<1e-5)))\n",
    "        indx_scale5 = np.argwhere(((-1e-12<=x0_EnSF) & (x0_EnSF<-1e-13)) | ((1e-13<=x0_EnSF) & (x0_EnSF<1e-12)))\n",
    "        indx_scale6 = np.argwhere(((-1e-13<=x0_EnSF) & (x0_EnSF<-1e-14)) | ((1e-14<=x0_EnSF) & (x0_EnSF<1e-13)))\n",
    "        indx_scale7 = np.argwhere(((-1e-14<=x0_EnSF) & (x0_EnSF<-1e-15)) | ((1e-15<=x0_EnSF) & (x0_EnSF<1e-14)))\n",
    "        indx_scale8 = np.argwhere(((-1e-15<=x0_EnSF) & (x0_EnSF<-1e-16)) | ((1e-16<=x0_EnSF) & (x0_EnSF<1e-15)))\n",
    "        indx_scale9 = np.argwhere(((-1e-16<=x0_EnSF) & (x0_EnSF<-1e-17)) | ((1e-17<=x0_EnSF) & (x0_EnSF<1e-16)))\n",
    "        \n",
    "        # # # x0_EnSF[indx_scale1[:, 0], indx_scale1[:, 1]] *= 5e1\n",
    "        x0_EnSF[indx_scale1[:, 0], indx_scale1[:, 1]] *= 1e2\n",
    "        x0_EnSF[indx_scale2[:, 0], indx_scale2[:, 1]] *= 1e3\n",
    "        x0_EnSF[indx_scale3[:, 0], indx_scale3[:, 1]] *= 1e4\n",
    "        x0_EnSF[indx_scale4[:, 0], indx_scale4[:, 1]] *= 1e5\n",
    "        x0_EnSF[indx_scale5[:, 0], indx_scale5[:, 1]] *= 1e12\n",
    "        x0_EnSF[indx_scale6[:, 0], indx_scale6[:, 1]] *= 1e13\n",
    "        x0_EnSF[indx_scale7[:, 0], indx_scale7[:, 1]] *= 1e14\n",
    "        x0_EnSF[indx_scale8[:, 0], indx_scale8[:, 1]] *= 1e15\n",
    "        x0_EnSF[indx_scale9[:, 0], indx_scale9[:, 1]] *= 1e16\n",
    "\n",
    "        sln_bar = reverse_SDE(x0=x0_EnSF.copy(), time_steps=euler_steps,  C=1, score_likelihood=score_likelihood)\n",
    "\n",
    "        ## v1a\n",
    "        sln_bar[:, indob_scale1] /= 1e2\n",
    "        sln_bar[:, indob_scale2] /= 1e3\n",
    "        sln_bar[:, indob_scale3] /= 1e4\n",
    "        sln_bar[:, indob_scale4] /= 1e5\n",
    "        sln_bar[:, indob_scale5] /= 1e12\n",
    "        sln_bar[:, indob_scale6] /= 1e13\n",
    "        sln_bar[:, indob_scale7] /= 1e14\n",
    "        sln_bar[:, indob_scale8] /= 1e15\n",
    "        sln_bar[:, indob_scale9] /= 1e16\n",
    "\n",
    "        # print(sln_bar[:, Size_U+Size_V+np.arange(0, Size_P)])\n",
    "        x0_EnSF = sln_bar.copy()\n",
    "\n",
    "    x_state[:, spa_indices] = sln_bar.copy()\n",
    "    x_state[:, Size_U+Size_V+np.arange(0, Size_P)] = np.clip(x_state[:, Size_U+Size_V+np.arange(0, Size_P)], -0.6, 0.6)\n",
    "    x_state[:, -1] = np.clip(x_state[:, -1], 0.95, 1.05)\n",
    "    \n",
    "    # print(x_state[:, Size_U+Size_V+np.arange(0, Size_P)])\n",
    "    U0_state = x_state[:, :Size_U].copy()\n",
    "    V0_state = x_state[:, Size_U+np.arange(0, Size_V)].copy()\n",
    "    q_batch = x_state[:, -1].copy()\n",
    "    print(q_Ref[i+1])\n",
    "    # print(q_batch)\n",
    "    est_save[[i+1], :] += np.mean(x_state, axis=0)\n",
    "    print(est_save[i+1, -1])\n",
    "    # get rmse\n",
    "    rmse_temp = np.sqrt(np.mean((est_save[[i+1], :] - state_timeextract[[i+1], :])**2))\n",
    "\n",
    "    # get time\n",
    "    t2 = time.time()\n",
    "    print(f'\\t RMSE = {rmse_temp:.4f}')\n",
    "    print(f'\\t time = {t2 - t1:.4f}')\n",
    "\n",
    "    # save information\n",
    "    rmse_all.append(rmse_temp)\n",
    "\n",
    "    # check divergence\n",
    "    if rmse_temp > 1000:\n",
    "        print('diverge!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c7883004-7eab-495b-b65c-e1ba6bc55b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_EnSF = est_save[:, :Size_U]\n",
    "V_EnSF = est_save[:, Size_U+np.arange(0, Size_V)]\n",
    "P_EnSF = est_save[:, Size_U+Size_V+np.arange(0, Size_P)]\n",
    "q_EnSF = est_save[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c058f846-e201-4a76-a66a-9215314f9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('ResultEnSF_Periodic_T100_10Obs_noise0001_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "                                                                     'q_EnSF': q_EnSF, 'rmse': rmse_all})\n",
    "# scipy.io.savemat('ResultEnSF_Periodic_T100_10Obs_noise01_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "#                                                                      'q_EnSF': q_EnSF, 'rmse': rmse_all})\n",
    "\n",
    "# scipy.io.savemat('ResultEnSF_Periodic_T100_7Obs_noise0001_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "#                                                'q_EnSF': q_EnSF, 'rmse': rmse_all})\n",
    "# scipy.io.savemat('ResultEnSF_Periodic_T100_7Obs_noise01_v1.mat', {'U_EnSF':U_EnSF, 'V_EnSF':V_EnSF, 'P_EnSF':P_EnSF, \\\n",
    "#                                                'q_EnSF': q_EnSF, 'rmse': rmse_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98344-717f-4fde-972b-38ee5ca5df7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
